{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UsingSavedEmotionAnalysisModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrfTr79jVNQN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRvjve-Mg-PL"
      },
      "source": [
        "# Mounting Google Drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAFZI0eXg2H_",
        "outputId": "4749e13a-6fb0-4594-9a20-bf5bd8cde03c"
      },
      "source": [
        "# Authorization User\r\n",
        "\r\n",
        "# installing necessary libraries to perform authorization\r\n",
        "\r\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\r\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\r\n",
        "!apt-get update -qq 2>&1 > /dev/null\r\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\r\n",
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "creds = GoogleCredentials.get_application_default()\r\n",
        "import getpass\r\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\r\n",
        "vcode = getpass.getpass()\r\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.24-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.24-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.24-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoXIvc-ThQYh"
      },
      "source": [
        "# Mount google drive as disk\r\n",
        "\r\n",
        "!mkdir -p drive\r\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4hF4ky_lRAs",
        "outputId": "290b93c0-7c6a-4259-9ae6-9e99e922c71b"
      },
      "source": [
        "# Check contents of folder working with\r\n",
        "import os\r\n",
        "\r\n",
        "os.chdir(\"/content/drive/Emotion_Analysis\")\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  drive  embeddings  models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kCn91sshf-L"
      },
      "source": [
        "# Append new folder/ path of folder to use to perform operations\r\n",
        "\r\n",
        "import sys\r\n",
        "sys.path.append('/content/drive/Emotion_Analysis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp4UTye9hqJi",
        "outputId": "2587437d-99c0-4dd7-adc1-0c7a5ba6a7cc"
      },
      "source": [
        "# not working   # Check the content of the new dir/ or folder working on \r\n",
        "# not working   # os.chdir(\"/content/drive/Emotion_Analysis\")\r\n",
        "# not working   # os.chdir(\"/\")\r\n",
        "# not working   # !ls \r\n",
        "\r\n",
        "# print out appended working folder path\r\n",
        "print(sys.path[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Emotion_Analysis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C7Ugr5aCliK"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNe4RK6oiEfj",
        "outputId": "f702a1e4-d2e7-4a29-b2ec-1d6a663fe91b"
      },
      "source": [
        "## =================== 1 =================== \r\n",
        "\r\n",
        "# 1. Import Data\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# text preprocessing\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "import re\r\n",
        "\r\n",
        "# plots and metrics\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "##### from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\r\n",
        "\r\n",
        "# preparing input to our model\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "# keras layers\r\n",
        "##### from keras.models import Sequential\r\n",
        "##### from keras.layers import Embedding, Bidirectional, LSTM, GRU, Dense"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d12aLOS4iSib"
      },
      "source": [
        "## =================== 2 =================== \r\n",
        "\r\n",
        "# Defining vector space dimension and fixed input size\r\n",
        "# Number of labels: joy, anger, fear, sadness, neutral\r\n",
        "##### num_classes = 5\r\n",
        "# Number of dimensions for word embedding\r\n",
        "##### embed_num_dims = 300\r\n",
        "# Max input length (max number of words) \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "max_seq_len = 500\r\n",
        "class_names = ['joy', 'fear', 'anger', 'sadness', 'neutral']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re2XHOJNiV2L"
      },
      "source": [
        "## =================== 3 =================== \r\n",
        "\r\n",
        "import io\r\n",
        "\r\n",
        "#Append your path\r\n",
        "# import sys\r\n",
        "# sys.path.append('/content/drive/Emotion_Analysis')\r\n",
        "\r\n",
        "\r\n",
        "# reference code\r\n",
        "# data_train = pd.read_csv('data/data_train.csv', encoding='utf-8')\r\n",
        "# data_test = pd.read_csv('data/data_test.csv', encoding='utf-8')\r\n",
        "# loaded_csv_file = pd.read_csv(io.BytesIO(data_to_load['filename.csv']))\r\n",
        "\r\n",
        "# data_train = pd.read_csv(io.BytesIO(data_to_load['data_train.csv']), encoding='utf-8')\r\n",
        "# data_test = pd.read_csv(io.BytesIO(data_to_load['data_test.csv']), encoding='utf-8')\r\n",
        "\r\n",
        "\r\n",
        "data_train = pd.read_csv('data/data_train.csv', encoding='utf-8')\r\n",
        "data_test = pd.read_csv('data/data_test.csv', encoding='utf-8')\r\n",
        "\r\n",
        "\r\n",
        "X_train = data_train.Text\r\n",
        "X_test = data_test.Text\r\n",
        "\r\n",
        "y_train = data_train.Emotion\r\n",
        "y_test = data_test.Emotion\r\n",
        "\r\n",
        "data = data_train.append(data_test, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA2D_d6ciatr"
      },
      "source": [
        "## =================== 4 =================== \r\n",
        "\r\n",
        "# defining a function to clean data\r\n",
        "\r\n",
        "def clean_text(data):    \r\n",
        "    # remove hashtags and @usernames\r\n",
        "    data = re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\r\n",
        "    data = re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\r\n",
        "    \r\n",
        "    # tekenization using nltk\r\n",
        "    data = word_tokenize(data)\r\n",
        "    \r\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZlSa3GkikyM"
      },
      "source": [
        "## =================== 5 =================== \r\n",
        "\r\n",
        "texts = [' '.join(clean_text(text)) for text in data.Text]\r\n",
        "\r\n",
        "texts_train = [' '.join(clean_text(text)) for text in X_train]\r\n",
        "texts_test = [' '.join(clean_text(text)) for text in X_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ubY-TXQiqQr"
      },
      "source": [
        "## =================== 6 =================== \r\n",
        "\r\n",
        "# Tokenizing and fitting the model using keras library\r\n",
        "\r\n",
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(texts)\r\n",
        "\r\n",
        "sequence_train = tokenizer.texts_to_sequences(texts_train)\r\n",
        "sequence_test = tokenizer.texts_to_sequences(texts_test)\r\n",
        "\r\n",
        "index_of_words = tokenizer.word_index\r\n",
        "\r\n",
        "# vacab size is number of unique words + reserved 0 index for padding\r\n",
        "vocab_size = len(index_of_words) + 1\r\n",
        "\r\n",
        "# print('Number of unique words: {}'.format(len(index_of_words)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6zXnbn3isqE",
        "outputId": "53f9a8be-f200-4075-ac09-47524cbfa9df"
      },
      "source": [
        "## =================== 7 =================== \r\n",
        "# Padding inputs so each of them have the same length\r\n",
        "\r\n",
        "# We defined maximun number of words for our texts and input size to our model has to be fixed - \r\n",
        "# padding with zeros to keep the same input lenght (longest input in our dataset is ~250 words)\r\n",
        "\r\n",
        "X_train_pad = pad_sequences(sequence_train, maxlen = max_seq_len )\r\n",
        "X_test_pad = pad_sequences(sequence_test, maxlen = max_seq_len )\r\n",
        "\r\n",
        "X_train_pad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,   119,    51,   345],\n",
              "       [    0,     0,     0, ...,    37,   277,   154],\n",
              "       [    0,     0,     0, ...,    16,     2,  1210],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,   876,     4,   909],\n",
              "       [    0,     0,     0, ...,     1,     6,   117],\n",
              "       [    0,     0,     0, ..., 10259,   173,    13]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovIrgIFLiuJi"
      },
      "source": [
        "## =================== 8 =================== \r\n",
        "# Categorizing labels\r\n",
        "\r\n",
        "encoding = {\r\n",
        "    'joy': 0,\r\n",
        "    'fear': 1,\r\n",
        "    'anger': 2,\r\n",
        "    'sadness': 3,\r\n",
        "    'neutral': 4\r\n",
        "}\r\n",
        "\r\n",
        "# Integer labels\r\n",
        "y_train = [encoding[x] for x in data_train.Emotion]\r\n",
        "y_test = [encoding[x] for x in data_test.Emotion]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCl3ZIREivmr",
        "outputId": "fb233272-6ce9-4778-c0e8-97497df95849"
      },
      "source": [
        "## =================== 9 =================== \r\n",
        "y_train = to_categorical(y_train)\r\n",
        "y_test = to_categorical(y_test)\r\n",
        "\r\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AAYWqjti4d2"
      },
      "source": [
        "## =================== 10 =================== \r\n",
        "# v2 load\r\n",
        "\r\n",
        "from keras.models import load_model\r\n",
        "loaded_model_v2 = load_model('/content/drive/Emotion_Analysis/models/bi_gru_w2vec_v2_30eps.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8KJ-43q-vD7",
        "outputId": "1657f93e-73f0-406e-93c7-e4d6c1263366"
      },
      "source": [
        "## =================== 11 =================== \r\n",
        "\r\n",
        "# time is imported to see how long each prediction took\r\n",
        "import time\r\n",
        "\r\n",
        "message1 = [\"I was very happy when my scholarship to go to flight school was approved after it had been cancelled\"]\r\n",
        "message2 = [\"I was very happy when my scholarship to go to flight school was approved after it had been cancelled, but now I'm sad that my dad died\"]\r\n",
        "message3 = [\"I was very happy when my scholarship to go to flight school was approved after it had been cancelled, but now I'm sad that my dad died and now I just won the lottery so I will celebrate my victory and I am very thrilled about it\"]\r\n",
        "message4 = [\"I was very happy when my scholarship to go to flight school was approved after it had been cancelled, but now I'm sad that my dad died and now I just won the lottery so I will celebrate my victory and I am very thrilled about it but then found out It all goes to my ex wife. I think I'm depressed now\"]\r\n",
        "message5 = [\"I was very happy when my scholarship to go to flight school was approved after it had been cancelled, but now I'm sad that my dad died and now I just won the lottery so I will celebrate my victory and I am very thrilled about it but then found out It all goes to my ex wife. I am super annoyed right now\"]\r\n",
        "\r\n",
        "message6 = [\"I'm verry\"]\r\n",
        "\r\n",
        "seq1 = tokenizer.texts_to_sequences(message1)\r\n",
        "seq2 = tokenizer.texts_to_sequences(message2)\r\n",
        "seq3 = tokenizer.texts_to_sequences(message3)\r\n",
        "seq4 = tokenizer.texts_to_sequences(message4)\r\n",
        "seq5 = tokenizer.texts_to_sequences(message5)\r\n",
        "seq6 = tokenizer.texts_to_sequences(message6)\r\n",
        "\r\n",
        "padded1 = pad_sequences(seq1, maxlen=max_seq_len)\r\n",
        "padded2 = pad_sequences(seq2, maxlen=max_seq_len)\r\n",
        "padded3 = pad_sequences(seq3, maxlen=max_seq_len)\r\n",
        "padded4 = pad_sequences(seq4, maxlen=max_seq_len)\r\n",
        "padded5 = pad_sequences(seq5, maxlen=max_seq_len)\r\n",
        "padded6 = pad_sequences(seq6, maxlen=max_seq_len)\r\n",
        "\r\n",
        "# prediction 1\r\n",
        "# start_time1 = time.time()\r\n",
        "prediction1 = loaded_model_v2.predict(padded1)  \r\n",
        "# prediction 2\r\n",
        "# start_time2 = time.time()\r\n",
        "prediction2 = loaded_model_v2.predict(padded2)\r\n",
        "# prediction 3\r\n",
        "# start_time3 = time.time()\r\n",
        "prediction3 = loaded_model_v2.predict(padded3)\r\n",
        "# prediction 4\r\n",
        "# start_time4 = time.time()\r\n",
        "prediction4 = loaded_model_v2.predict(padded4)\r\n",
        "# prediction 5\r\n",
        "# start_time5 = time.time()\r\n",
        "prediction5 = loaded_model_v2.predict(padded5)\r\n",
        "# prediction 6\r\n",
        "# start_time6 = time.time()\r\n",
        "prediction6 = loaded_model_v2.predict(padded6)\r\n",
        "\r\n",
        "print('Message-1: ' + str(message1))\r\n",
        "print('prediction-1: {}'.format(class_names[np.argmax(prediction1)]))\r\n",
        "print('')\r\n",
        "\r\n",
        "print('Message-2: ' + str(message2))\r\n",
        "print('prediction-2: {}'.format(class_names[np.argmax(prediction2)]))\r\n",
        "print('')\r\n",
        "\r\n",
        "print('Message-3: ' + str(message3))\r\n",
        "print('prediction-3: {}'.format(class_names[np.argmax(prediction3)]))\r\n",
        "print('')\r\n",
        "\r\n",
        "print('Message-4: ' + str(message4))\r\n",
        "print('prediction-4: {}'.format(class_names[np.argmax(prediction4)]))\r\n",
        "print('')\r\n",
        "\r\n",
        "print('Message-5: ' + str(message5))\r\n",
        "print('prediction-5: {}'.format(class_names[np.argmax(prediction5)]))\r\n",
        "print('')\r\n",
        "\r\n",
        "print('Message-6: ' + str(message6))\r\n",
        "print('prediction-6: {}'.format(class_names[np.argmax(prediction6)]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message-1: ['I was very happy when my scholarship to go to flight school was approved after it had been cancelled']\n",
            "prediction-1: joy\n",
            "\n",
            "Message-2: [\"I was very happy when my scholarship to go to flight school was approved after it had been cancelled, but now I'm sad that my dad died\"]\n",
            "prediction-2: sadness\n",
            "\n",
            "Message-3: [\"I was very happy when my scholarship to go to flight school was approved after it had been cancelled, but now I'm sad that my dad died and now I just won the lottery so I will celebrate my victory and I am very thrilled about it\"]\n",
            "prediction-3: joy\n",
            "\n",
            "Message-4: [\"I was very happy when my scholarship to go to flight school was approved after it had been cancelled, but now I'm sad that my dad died and now I just won the lottery so I will celebrate my victory and I am very thrilled about it but then found out It all goes to my ex wife. I think I'm depressed now\"]\n",
            "prediction-4: sadness\n",
            "\n",
            "Message-5: [\"I was very happy when my scholarship to go to flight school was approved after it had been cancelled, but now I'm sad that my dad died and now I just won the lottery so I will celebrate my victory and I am very thrilled about it but then found out It all goes to my ex wife. I am super annoyed right now\"]\n",
            "prediction-5: anger\n",
            "\n",
            "Message-6: [\"I'm verry\"]\n",
            "prediction-6: neutral\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}